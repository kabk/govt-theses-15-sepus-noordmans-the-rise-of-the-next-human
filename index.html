<!DOCTYPE html>
<html lang="en">

<head>
  <script src="js/modernizr.custom.js"></script>
  <script src="js/jquery.min.js"></script><style type="text/css"></style>

  <script>
  $(function() {
    $('a[href*=#]:not([href=#])').click(function() {
      if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'') && location.hostname == this.hostname) {

        var target = $(this.hash);
        target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
        if (target.length) {
          $('body,html').animate({'scrollTop': target.offset().top}, 1000);
          return false;
        }
      }
    });
  });
  </script>


<title>Sepus Noordmans - Thesis</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/style.css" type="text/css" media="screen" title="no title" charset="utf-8"/>





</head>
<header>
Thesis – What is the purpose of personifying artificial intelligence and robotics? <br> Sepus Noordmans – GOvt.4A
</header>

<body>

  <div id="content" a name="content">
    <ol><a href="#one">Preface</a></ol>
    <ol><a href="#two">Introduction</a></ol>
    <ol><a href="#three">Chapter 1: Robotics and Artificial Intelligence</a></ol>
    <ol><a href="#four">Chapter 2: That what we perceive</a></ol>
    <ol><a href="#five">Chapter 3: Dread of personification</a></ol>
    <ol><a href="#six">Chapter 4: Where Graphic Design can help</a></ol>
    <ol><a href="#seven">Conclusion</a></ol>
    <ol><a href="#eight">Sources</a></ol>
    <ol><a href="#nine">Abstract</a></ol>
    <ol><a href="#ten">Images</a></ol>
  </div>




<div id="article">
    <div style="padding-bottom:100px;"><a name='one' />
      <h1>PREFACE</h1>
      <p>none yet</p>
    </div>

    <div style="padding-bottom:100px;"><a name='two' />
      <h1>INTRODUCTION</h1>
      <p>none yet</p>
    </div>

<div style="padding-bottom:100px;"><a name='three' />
<h1>CHAPTER 1: ROBOTICS AND ARTIFICIAL INTELLIGENCE</h1>
<p>Robotics and artificial intelligence are two completely separate technologies, though they could be the basics of a fully independent robot. In this we can see similarities with humans. The robotics would function as the muscles and joints of our human bodies, granting the machine movement in any possible direction. And the artificial intelligence would be the human brain, or more accurately said; the nerve system, here is where the ‘thinking’ happens. This comparison between robotics and AI and the humans is the framework for this thesis. I will introduce the world of robotics and intelligence to create a better understanding of the terms and the thesis question. It’s important to understand the technology and what it could potentially achieve, to understand why there is an interest in copying the human anatomy and brain in technological developments.</p> 

<p>Artificial Intelligence</p>
<p>Artificial intelligence (AI) as the science and engineering of making intelligent machines, especially intelligent computer programs said John McCarthy in 2007 1. And the meaning of intelligence is a computational ability to achieve certain goals. It would make computer programs capable of understanding certain data and – if the AI is designed to it– can process this information and eventually respond to it by executing a new task. To give a rough example, when asking Apple’s Siri a question, it analyses your spoken sounds and transforms these into words. Then it searches for an answer on the internet and presents information back to you. But AI is a very complex and big research, in order to narrow it down I will focus on two main types of artificial intelligence, weak AI and strong AI.</p> 

<p>Weak (or narrow) AI means that the machine that is running the AI can appear intelligent, but it only simulates the intelligence, thus it can never be aware of what it is actually doing. In other words, the program is only following a strict set of instructions that it needs to execute. An example of weak AI is spell-checking software. When typing a wrong word the computer instantaneously runs through the dictionary looking for words with the same letters and hands back a list with several potential correct words, after finishing this algorithm it can eventually display a new list where the user can select and correct the mistake, or it does so itself. It seems that the computer is intelligent because we can feel like it understands what we want to write and that it is assisting us by correcting the fault, but it only executes a series of tasks in order to solve a problem.</p>

<p>Strong AI is when a (hypothetical) machine’s intelligence is completely functioning and equal to a human’s intelligence. Meaning that it would be possible for the machine to duplicate the full range of human cognitive capabilities. It will be able to imagine, think, reason, etc., activities that we do with our brains. Jack Copeland says; “The reputation of this area of research has been damaged over the years by exaggerated claims of success that have appeared both in the popular media and in the professional journals. At the present time, even an embodied system displaying the overall intelligence of a cockroach is proving elusive, let alone a system rivalling a human being.” 4  A proven strong AI is as of now non-existent, but researchers and engineers are still developing this technology. It might become a reality in a not-too-distant future. Ray Kurzweil from Google believes that in 2029, computers will be able to do all the things that we humans are able to do, but even better.2 By that time, we can possibly see a new form of human evolution.</p>

<p>There are many systems that have a weak AI, limited to perform a certain task. These tasks are executed outside of human comprehension and control, we can not perceive what is happening at the moment. There are many risks and fears that come with AI, and not every citizen is feeling safe about the idea of software controlling aspects of our daily lives. This could be an unconscious assistance that is for example the autocorrect or speech recognition which is in most cases is by default installed on our smartphones. Or it could be bigger, like the complex HFT (High Frequency Trading) algorithm that controls the financial markets. The very same algorithms that caused the flash crash in May 2010.</p>

<p>"Narrow AI could knock out our electric grid, damage nuclear power plants, cause a global-scale economic collapse, misdirect autonomous vehicles and robots… Weak, narrow systems are extremely powerful, but they’re also extremely stupid; they’re completely lacking in common sense. Given enough autonomy and responsibility, a failed answer or a wrong decision could be catastrophic.” 6 As said in 2013 by George Dvorsky. Even though the description of weak or narrow AI sounds harmless, it can do great damage to our digital systems because of the incredible speed a computer can harness. When an AI is the cause of one of these catastrophic events, we might possibly be to late to realize it.</p>

<p>Strong AI is the type of AI that is often being debated, there are endless stories and films in our popular culture about a type of AI that could either be a true friend, a savior of mankind, or the end of the human race. In contrast to weak AI, strong AI is not limited. The fear that is often connected to strong AI is the ability that it can develop itself, to improve, the same way that humans improve their capabilities over time. The reason this debate is ongoing is that a learning, strong AI is likely to surpass its human creators. It becomes smarter, faster, more developed and once surpassed, the program would then be completely out of our control.</p>

<p>Stephen Hawking, a famed physicist mentions in a column in The Independent; “Success in creating AI would be the biggest event in human history. Unfortunately, it might also be the last, unless we learn how to avoid the risks.”5And he is not the only person warning the people about AI, Elon Musk, founder of SpaceX, co-founder of PayPal and Tesla Motors, shares the very same thought. They both believe that if we do not limit a strong AI, the dangers suddenly increase because of its superior capabilities. If we are not capable of understanding the situation after the AI has been created, we will lose control of what we thought to be ours. We humans have evolved into intelligent beings but the point when a machine outsmarts us, what will our place then be?</p>

<p>Robots</p>
<p>Robots are mechanical devices that are capable of independently executing tasks after it has been given a string of computational data. Robots are developed to complete it’s tasks without constant human input. A very obvious but clear example of a robot, that doesn’t come from science-fiction, are the huge mechanical arms that are working in the production lines of car factories today. These arms are programmed to execute certain movements and tasks when a yet-to-build-car passes by on the production line. These robots work with great precision once it has been given the correct instructions and will never, unlike us humans, grow tired of its job. Leading to a situation where some tasks involving humans have been replaced by robots in the car production line.</p>

<p>But robots are not only to be found in the industrial sector, they can now be found in our homes as well. It has not become a standard yet, but a simple example of a robot that is finding its purpose amongst our family is the automatic vacuum-cleaner, lawn mowers, self-cleaning toilets and so on. Small devices such as the vacuum cleaner, will once it’s receiving an instruction, start to clean while moving around inside the space it currently is in. It notices when to stop after ‘feeling’ a wall or another impassible object and continues it’s cleaning task by making a small turn in another direction, once done it can find its own way back to the recharging station. It will completely take away the time-consuming effort of vacuuming.</p>

<p>So, generally speaking robots are currently being used to replace humans tasks that are mundane, dangerous or exhausting. They can be deployed in areas which are not easily accessible for humans, it could be either working deep down in the ocean or up above, in outer space. Robots functionality and abilities sounds like an life changer in a good way, by replacing humans for work that is either too difficult or unwanted, it also changes lives in a negative way. One example can be how robotics have been blamed for a rising unemployment, also known as technological unemployment. A discussion that has been going on for a very long time, and has been called the Luddite Fallacy under the economics. This is just an example to show the implications of robotics in the our daily lives.7</p>

<p>“Humans will continue to be useful workers because of things like empathy, creativity, judgment, and critical thinking. Traditionally, increased productivity correlates with economic growth and job growth, since human labor has historically driven production. A robot workforce, however, can drive productivity and growth on its own, eliminating jobs in the process. That might mean the whole paradigm of exchanging labor for pay starts to break down. … By eliminating the need for people to work, robots would free us up to focus on what really makes us human. The scariest possibility of all is that only then do we figure out what really makes us human is work.” says Wired Magazine’s Marcus Wohlsen. Robots are constantly being criticized, today because we are afraid of the fact it causes a technological unemployment, or our way of ‘doing’ stuff. Or maybe because the engineer designs it in a way, it would be physically superior than we are.</p>

<p>This thesis will depict a situation about a combination of robotics with a strong AI. Basically the human replicated into a machine. A sentient, conscious, independent machine. What are the reasons to personify robotics and artificial intelligence? Why is there a development in duplicating our species into a mechanical and digital form? Will we witness another step in human evolution?</p>
</div>

<div style="padding-bottom:100px;"><a name='four' />
<h1>CHAPTER 2: THAT WHAT WE PERCEIVE</h1>
<p>Modern visual culture has never been so prominent as it is today. Inventions like the printing press, the screen and the internet keep surrounding us with static and moving imagery, both in public and private space. Science-fiction can in many ways function as a window through which we can see our potential future on Earth. None of what you see is real, it merely depicts a thought, a story or close-to scientific truth.</p>

<p>  The view of our society upon the topic of robots and AI is greatly influenced by the films we see in popular culture. Storylines for these sci-fi films can depict a dystopian view, it is common to show how powerful computers and robotics can be. The AI in the Terminator (1984/2015) called Skynet is a great example of a dystopian situation, the AI means to exterminate the human race. Another example is in I, Robot (2004). Here it initially shows a situation where robots are peaceful personal assistants for the future human civilization, but it ends with an attempt of a strong AI commanding newer robots to control the humans under slavery in order to prevent the human race from destroying itself. This depiction of our future, where robotics and AI overrule the human kind is common when discussing the fate of mankind since the invention of the technology. Does that mean that by default, we already accept that these robots are already better than us, their creators? Is that the reason we easily consider them as potential enemies? That in the end they would shift the hierarchy pyramid so that  entire mankind is placed lower than them?</p>

<p>With the capabilities of current technology in moviemaking, the sci-fi genre is living it’s golden age. But before the rise of the computers, robots or monstrous characters were being performed by actors in clunky costumes. We will look at the looks of several robotics and AI to show how human we design them, this vision is where the development learns a lot from. I want to note that within in chapter there will be spoilers regarding the films that are being mentioned in here. </p>


<p>Hal 9000 – 2001: A Space Odyssey</p>

<p>Stanley Kubrick produced and directed what I consider one of the most important sci-fi film in the 60’s. 2001: A Space Odyssey (1968) is a story where an AI –without a robotic form– is the primary antagonist in the story. It is my personal favorite and arguably a classic within the genre of space stories. The antagonist is called Hal-9000 (Heuristically programmed ALgorithmic computer). It is a computer that is in control of the Discovery One spacecraft. Hal interacts with the astronauts aboard, functioning as a host of the spacecraft and takes care of its guests, among them is the protagonist David “Dave” Bowman. </p>

<p>During the film, Hal the computer, is no longer considered to be an ‘it’, but is seen as a person and becomes a ‘he’. That is because the AI is very similar to a human mind and has a ‘gender’ because of his monotonous male voice. It is a sentient computer, meaning that it is able to understand the human emotions and is able to relate to humans. He is conscious and is capable of making his own decisions. Which makes Hal an example of a strong AI (Chapter 1). And because of this intellectual behavior we identify Hal as a human, even though he is not mobile, which would limit him to be in only one spot. Hal as an AI is controlling the entirety of the ship from every given location, he is an ephemeral entity, comparable to todays internet system called the ‘cloud’. Nevertheless Hal is not a physical machine with absolutely no human anatomy, we as viewers (possibly) still recognize him –or better said, the machine– as if he is one of ‘us’. And that is due to two aspects of his character. He thinks like us and he talks like us. </p>

<p>What makes Hal more machine-like is that he has no human or human-like face. His iconic ‘face’ is a rectangular panel with a iconic red ‘eye’ –a camera to perceive– and some other small features. Meaning that he gives no point of reference to understand his emotion through facial expression. This perceptive ability is a skill and a go-to for humans to feel or understand the other persons current thoughts. It is a non-verbal universal language of our social species. “It serves as a window to display one's own motivational state. This makes one's behavior more predictable and understandable to others and improves communication. The face can be used to supplement verbal communication. A quick facial display can reveal the speaker's attitude about the information being conveyed.”</p>

<p>When Hal mentions that he can understand and feel an emotion, we suddenly identify this situation as inhuman. In the deactivation scene of Hal, he thinks that Dave should sit down and reconsider the situation, after no response Hal continues with acknowledging his own mistakes, and trying to convince Dave to stop with the deactivation.</p>

<p><i>HAL: Look Dave, I can see you're really upset about this. I honestly think you ought to sit down calmly, take a stress pill, and think things over.<br>
  HAL: I know I've made some very poor decisions recently, but I can give you my complete assurance that my work will be back to normal. I've still got the greatest enthusiasm and confidence in the mission. And I want to help you.<br>
  [HAL's shutdown]<br>
  HAL: I'm afraid. I'm afraid, Dave. Dave, my mind is going. I can feel it. I can feel it. My mind is going. There is no question about it. I can feel it. I can feel it. I can feel it. I'm afraid…</i></p>

<p>Hal mentions that he is afraid, meaning that he/it understands the human concept of fear. But the viewer can’t hear any differences in his monotone voice, nor perceive that Hal is truly experiencing fear. Eventually, these aesthetic limitations rose a confusion which made Hal unidentifiable as a being, leaving him drift between human and machine.</p>


<p>Gerty – Moon</p>

<p>  After the release of 2001: A Space Odyssey, Hal caused an increase in societal anxiety towards autonomous computers as the film shows both potential risks and power of AI technology. In contrast to this film, director Duncan Jones released Moon in 2009. A sci-fi film about moon-based employee Sam Bell, working solely on an automated mining operation. Sam is accompanied by Gerty, a computer that controls the base and is caretaker of Sam during his three-year labor on the moon. Just like Hal, Gerty is a strong AI, but it has additional robotic features. </p>

<p>  Unlike Hal, Gerty has his own physical ‘body’. A big grey chassis that is fixed to a rail system, which allows him to move towards and inside certain spaces in the base. Gerty’s physical presence makes Sam less lonely as he is able to search and find the machine and meet him ‘in person’. By granting Gerty this non-ephemeral form, viewers of the film perceive him closer to be a being, not necessarily as an object. “Robots that closely resemble a human being deal with and affect people much differently than a less anthropomorphic one. Physical appearance does not limit a robot's interaction with humans though it greatly enhances it.” It is a feature that works out positive for the relationship between Sam and Gerty, and also between Gerty and the audience. His clunky chassis is not only dead weight, but makes him a friendly-looking character. Another feature of Gerty that made him less frightening, is that he has an actual face. Not a human face, or any attempt to make a humanoid version of it, but a simple digital representation of a face.</p>

<p>For example, Gerty has an eye, a white ‘blinking’ camera that is more friendly than Hal’s red and fear-inducing camera. But this ‘eye’ is not what Sam looks at when interacting with Gerty. He has a feature that makes him more approachable. Mounted on the front of his chassis is a small screen that is able to display several emoticons, the same that we use in text-messaging. Granting Gerty the low-end ability to communicate with emotions, Sam is able to relate to Gerty better because of he is can express ‘feelings’ such as smiling, frowning, crying, and being confused. It greatly enhances the conversation between the two characters and for the viewers. </p>

  <p><i>
  Gerty: Two weeks to go Sam<br>
  Sam: Two weeks to go buddy!<br>
  </i></p>

<p>Throughout the film, Gerty is taking care of Sam by waking him up and asking how he feels or sharing activities like cutting his hair. Sam recognizes him as not only his colleague but also as a friend on the base, by interacting with Gerty as a person. And be able to really listen to his stories and asking favors. The relationship between man and machine is a very important storyline in the movie. Even though it is not the primary story, a great part of the film is about how Sam interacts with Gerty, and how a robot can be a friend of a human. Gerty his friendly appearance and behavior caused a positive shift within the topic of robotics and AI, improving the view where 2001: A Space Odyssey left a negative perspective. One of Gerty’s features has later been implemented on Baxter, a robot that is one step closer in the personification of robots. Baxter is not a movie character, he is part of the current robotics that I will discuss later in this chapter.</p>


<p>C-3PO and R2-D2 – Star Wars</p>

<p>The iconic robotic duo; C-3PO and R2-D2 are possibly the funniest and most kind representations of robotics and AI in popular culture. A shiny golden robotic figure and his companion, a blue/white rolling machine are important characters in the science-fiction world, and the popular Star Wars cast would not be complete without these two adventurers. C-3PO’s design is defined as humanoid, a mechanical construction that strongly resembles a human being. And C-3PO does this in many areas in where we can recognize a human. Such as having a similar appearance, same anatomy, predictable behavior and speaking the same language as the humans in the films. It has a face with human features, a pair of eyes with eyebrows, a vague hint of a nose, a mouth and a torso with two legs and arms. C-3PO is able to walk, clunky because it has to ‘look’ like a robot. R2-D2 however, is designed not to become humanoid but a robot in core. His looks are far from being any human, but the sounds that R2-D2 produces have a slight human hint. The following is a snippet from an interview with Ben Burtt, an Oscar winning sound-designer, sound designing for the films E.T. (1982) and Wall-E (2008). In a conversation about his designs for R2-D2, he mentions the human aspect: </p>

<p>“Yet it was a machine, it didn’t have a face with a smile or a mouth, eyes or ears. And it couldn’t speak English and it couldn’t even mouth words. At least Chewbacca could make kind of animal sounds, which you could attribute a personality to. The initial experiments coming up with R2’s voice were all directed to make a machine-type of language that would come out of a computer, out of a robot. And all of the voices were very interesting, which I think that I made. But they all seem to lack a certain human quality, they seem to machinelike. And R2 wasn’t just a machine but also a lovable assistant robot. ” </p>

<p>Ben mentions later on that he designed the sounds that were similar to baby-sounds. A sound that a little infant would be making when it’s learning to talk. “So the idea came up to combine this sort of human sound, with the electronic sounds. That way we might be able to have the character of a machine but get the personality and the emotion of a living organism”. But R2-D2 remains a robot, the twist of giving R2-D2 goofy and unclear sounds makes him the character a cute machine. Wall-E has a similar appearance as that of R2-D2, this little robot also evades the humanoid aspect completely. And what Pixar’s design of this character does great in this design is, next to his primitive vocabulary, is that they designed him being cute. He has shiny glassy eyes that reminds us of a baby and a rather sad or shy look to his face.</p>


<p>The Uncanny Valley</p>

<p>The viewers of Star Wars adore R2-D2 more that its humanoid counterpart C-3PO because he is evading what is called the Uncanny Valley. This mysterious term was coined in the 1970’s by Japanese roboticist Masahiro Mori. He notices that, the more human his robots become in behavior and appearance, he receives more positive reactions, however, when the robots look extremely close to humans but just not enough to be convincing, people find them to be visually revolting. The Uncanny Valley is this gap between almost human and completely human. Almost forty years after its introduction, both robot designers as film makers still struggle with the valley. Certain movies receive big criticism when their character becomes too human, but fails at mimicking it. We detect slight imperfections because our brain has expectations of how a human should behave, but the subject becomes strange when it doesn’t. This doubt can make us perceive these robots/humanoids as if we are watching a unhealthy or sick human. Karl MacDorman says in 2005: “When a humanlike robot elicits an eerie sensation it is because the robot is acting as a reminder of mortality”. To give an example; when a human-like robot does not move, we perceive it –according to Mori’s graph– as a dead being. It stirs up a fear and leaves us uncomfortable watching the subject attempt and fail in mimicking humans.</p>

<p>The Uncanny Valley is a hypothesis, but proves to be very useful for robot designers and film makers. I experience the very same feeling when seeing an animatronic for example. And there are scientists that doubt the existence of this valley. Ayse Saygin, a cognitive scientist at the University of California says: “We still don't understand why it occurs or whether you can get used to it, and people don't necessarily agree it exists.” The Uncanny Valley is a mental phenomenon that scientists can’t yet explain. Except we as viewers notice and feel uncomfortable when seeing a subject that is deep down in the valley. </p>

  Visualize some examples of uncanny robots.


<p>Baxter</p>

<p>Right now, the development of robotics and (narrow) AI is flourishing. Many robots are being developed and build, either in concept or final stages. One of them is Baxter, designed by Rethink Robotics and is already working in several companies. As mentioned in chapter 1, many of the current robotics are deployed in industrial environments. Robotics that do heavy-duty work like the robotic arms in a car-line factory. Baxter is not the same as those, but it does replace mundane tasks like packaging or any other form of repetitive movements. He is designed to work next to us. Rethink Robotics welcomes you wit; “For decades, production robots have been separated from people by protective cages, programmed only by specialized engineers, and affordable by a small percentage of manufacturers. Rethink Robotics is changing that paradigm.”. With their mission, Rethink Robotics is making a step closer to the people with Baxter. One way they do this is by ‘teaching’ Baxter the movements you want him to do. By physically guiding him –positioning his arms– and implement certain tasks for him to perform, he will then repeat the given orders and will be fully functional.</p>


<p>Jibo</p>

<p>Baxter has made a step closer to our homes, Jibo is already on our doorstep. Jibo started out as crowdfunding project. The project has reached its $100.000 goal in only four hours, and at the 14th of September, Jibo has an approximate of $2.2 million dollars invested. Jibo is an intelligent personal assistant, slightly comparable to Siri on our phones as both of them are a weak AI. For example: Jibo can notify you when you have new emails, or remind you of an appointment. But where Jibo goes a bit further, is that he can educate through apps, or his 360 degrees rotational body, the interaction to human and machine is getting closer. Jibo is attempting to be a family friend and will help in every way he can. This gets emphasized in the introduction clip on the website where the narrator explicitly calls Jibo a ‘he’.</p>

<p>Next to the massive amount of investing that has been pledged by enthusiasts, there are also many people that fear the coming of Jibo. By reading the comments that are placed underneath the introduction clip on YouTube, people still fear of a dystopian future where robots control or destroy mankind. This is a rather stereotypical view upon this technology that has greatly been influenced by the trails of popular culture that I’ve mentioned before:</p>

<p><i>“I'm not sure if Jibo is really neat, or really disturbing. Is there a uncanny valley for household devices?﻿” - Kee Hinckley</i></p>

<p><i>“I had no idea AI was so advanced and consumer ready... or is it possible that they have over-sold and over-stated the reality of this thing? Is it really as fluent as it is being portrayed, here? Really? Well, it's pretty neat, and if it is actually as they are selling it, here, it's even a little bit scary.﻿” - Richard Lucas</i></p>

<p><i>“.....this is the beginning of the end.﻿” - George Baum</i></p>

<p>The project has not only been in the shadows, it has received many positive comments since its introduction from technology websites. On Mashable they say: “Jibo isn't an appliance, it’s a companion, one that can interact and react with its human owners in ways that delight instead of disturb. Jibo supports the human experience, but does not try to be human.” The team behind Jibo, lead by Dr. Cynthia Breazael is attempting to shift towards a more positive perspective upon robotic technology. She intends to do so by learning how humans and robots could interact. What Jibo is doing good in terms of design, is that is is not even approaching the Uncanny Valley.</p>

<p><i>“More importantly, Jibo skirts way, way around the uncanny valley — there’s little in it that could be confused for a human. Jibo skirts way, way around the uncanny valley — there’s little in it that could be confused for a human. “It’s a robot, so let’s celebrate the fact it’s a robot,” said Breazeal as she explained the design decisions behind Jibo. Yet it can act in human ways that are compelling”</i></p>

<p><i>“…and automatically swiveling to pay attention to someone else speaking nearby it. It moves, in other words, as one might expect a living thing to. Breazeal calls this “attuned reciprocity” It’s the idea of not only paying attention to visual cues, but responding in a reciprocal or mutual way. It’s something humans do all the time. “</i></p>

<p>Also Jibo has a similar technique that Baxter and Gerty use. All three of them are making use of a screen to display facial expressions and emotions. There is a pattern with applying this technique, it is being used on several different kinds of robotics and it now seems that it is one of the most important design aspects to familiarize this technology with mankind.</p>



<p>Other AI in popular culture</p>

  Images?




<p>We will attempt to develop robotics and AI until they can be very comparable to us humans. As seen in popular culture it is a very common way to think about this topic as a threat to human kind, we are afraid of superior capabilities. In popular culture we take human elements and ‘computerize’ these into a character. As the monotonous and mostly unemotional voice of Hal makes us realize that it is not human, but showing human behavior blurs the border. Or where Gerty has a completely mechanical body, but duplicates facial expressions to appear more human in the film. We can learn from these characters how to design personified robotics. The uncanny valley is in my opinion real, we don’t need to anthropomorphize our own creations around us. And we need to evade the valley, personifying robotics and AI might just mean to not make it human at all.</p>
</div>

<div style="padding-bottom:100px;"><a name='five'/>
<h1>CHAPTER 3: DREAD OF TECHNOLOGY</h1>
<p>none yet</p>
</div>

<div style="padding-bottom:100px;"><a name='six'/>
<h1>CHAPTER 4: WHERE GRAPHIC DESIGN CAN HELP</h1>
<p>none yet</p>
</div>


<div style="padding-bottom:100px;"><a name='seven'/>
<h1>CONCLUSION</h1>
<p>none yet</p>
</div>

<div style="padding-bottom:100px;"><a name='eight'/>
<h1>SOURCES</h1>
<p>none yet</p>
</div>

<div style="padding-bottom:100px;"><a name='nine'/>
<h1>ABSTRACT</h1>
<p>We live in the rapid changing Information Age, a time in which we grow to live in a symbiosis with technology. It has become a part of our daily routine, continuously evolving into more complicated inventions.
Advanced technology is on the verge of becoming a part of our households. One example is the development of a personal robot with it’s own artificial intelligence built to assist us with our daily tasks. A seemingly innocent invention, but some researchers mean that this can be the biggest mistake in human history.
Popular-culture has attempted to to visualize robotics based on human aesthetics, creating our technological copies. A tendency that is also seen within the development of robotics; it’s anatomy, it’s way of thinking and even the way it speaks has strong resemblances to humans. How would the way humans perceive robotics change when we change “it” to a “he” or “she”? What is the purpose of personifying such comprehensive and inhuman machines?
These are questions I will attempt to answer by looking at the situation from two angles. By presenting the reasons for and against personifying robotics I want to create a better understanding of the technological development. Why it looks like it does, how it will infiltrate our daily lives and look at how human behavior towards robotics might change with it.<br><br>
What is the purpose of personifying artificial intelligence and robotics? </p>
</div>

<div style="padding-bottom:100px;"><a name='ten'/>
<h1>IMAGES</h1>
<img src="img/hal.jpg"/>
<img src="img/gerty.jpg"/>
<img src="img/maria.jpeg"/>
<img src="img/jibo.png"/>
<img src="img/c3po.jpg"/>
<img src="img/cortana.jpg"/>
<img src="img/edi.jpg"/>
<img src="img/samantha.jpg"/>
<img src="img/kitt.jpg"/>
<img src="img/walle.jpg"/>

</div>





<div class="totop">
  <a href="#content">Back to top</a>
</div>


</div>
</body>
